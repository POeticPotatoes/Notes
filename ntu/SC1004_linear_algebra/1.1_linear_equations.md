# Linear Equations
> Assoc Prof Liang Tien CHIA, Clement (67906241)

A Linear Equation in $n$ variables is one expressed in the form

$a_1x_1+a_2x_2+...+a_nx_n=b$

where $a1, a2, ... , a_n$ and $b$ are constants and are not **all** zero

A general **linear system** of $m$ equations in $n$ unknowns $x_1, x_2,...,x_n$ can be written as

$a_{11}x_1+a_{12}x_2+...+a_{1n}x_{n} = b_1\\
a_{21}x_1+a_{22}x_2+...+a_{2n}x_{n} = b_2\\
\vdots\\
a_{m1}x_1+a_{m2}x_2+...+a_{mn}x{n} = b_m\\
$

A **homogeneous** system is when $b_1=b_2=...=b_m=0$. Otherwise, the system is **non-homogeneous**.

A **consistent** system has >0 solutions (a sequence of $n$ numbers $s_1, s_2,...,s_n$ for which the substitution $x_1=s_1, x_2=s_2,...,x_n=s_n$ makes all equations true)

A solution is **unique** if it is the only solution to the system.

There can **only** be 0, 1, or *infinitely many* solutions.

**All homogeneous systems** are consistent as they have a solution when $x_1=x_2=...=x_n=0$ (obviously, hence it's called the **trivial solution**)

## Conversion to Matrix Form

$5x+y=3\\
 2x-y=4$

Coefficient Matrix: $\begin{bmatrix}
5&1\\
2&-1
\end{bmatrix}$

Augmented Matrix: $\begin{bmatrix}
5&1&3\\
2&-1&4
\end{bmatrix}$

$m\times n$ means $m$ rows and $n$ columns

### Determining Consistency and Uniqueness
**Consistency** and **uniqueness** may be determined by converting the augmented matrix into a **row equivalent** matrix

#### Row Equivalence
Two matrices are row equivalent if an arbitrary sequence of **Elementary Row Operations (EROs)** transforms one into the other:
1. Multiply a row by a **non_zero** constant
2. Interchange two rows
3. Add a constant times one row to another

> Example of operation #3: $\begin{bmatrix}1&2&1\\1&3&4\end{bmatrix}$ becomes $\begin{bmatrix}1&2&1\\1&3&4\end{bmatrix} + \begin{bmatrix}0&0&0\\2&4&2\end{bmatrix} = \begin{bmatrix}1&2&1\\3&7&6\end{bmatrix}$

#### Row Echelon Form
A matrix is in **Row Echelon Form** if:
1. Any rows that consist entirely of zeros are at the bottom of the matrix
2. Between any adjacent pairs of rows, the first nonzero element (the **pivot**), in the lower row occurs farther to the right than the pivot in the higher row.

A matrix is in **Reduced Echelon Form** if:
1. The matrix is in row echelon form
2. In every column containing a pivot, the pivot has value 1 and all other elements are 0

#### Gaussian Elimination 
States that a matrix not in row echelon form can be transformed into one through a sequence of EROs. A different sequence may lead to a different matrix.

#### Gauss-Jordan Elimination
States that a matrix not in reduced row echelon form can be transformed into one (through a sequence...). The resulting matrix is **unique**.

It consists of 2 parts: a **forward-phase** where zeros are introduced below the pivots and a **backward phase** where zeros are introduced above the pivots and the pivots are transformed to 1.

Using **only forward elimination** gives a row-echelon-form (which is gaussian elimination).

#### Determining Consistency
Once an augmented matrix is converted to its **row echelon form**, inconsistencies can be exposed.

Any row that is valid for all solutions (ie. a zero row) means the system has infinite solutions.

Further reducing the matrix into reduced row echelon form gives us a new system of equations, where **pivots** become **leading variables**, and the rest become **free variables** which express the pivots.

In conclusion:
1. Write the augmentedmatrix
2. Obtain an equivalent augmented matrix in row echelon form, and determine if it is consistent.
3. Continue row reduction to obtain the reduced row echelon form.
4. Write the system of equations corresponding to the matrix obtained
5. Rewrite each nonzero equation so that its one basic variable is expressed in terms of free variables

## Linear Combination of Vectors
Given vectors $v_1, v_2,...,v_p$ in $\R^n$ and and given scalars $c_1, c_2,...,c_p$,   
the vector: 

$y = c_1v_1 +...+ c_pv_p$

is called a **linear combination** of $v_1,...,v_p$ with weights $c_1, c_2,...,c_p$, and can be expressed as a **linear system**.


## Span
$Span\{c_1v_1+...+c_pv_p\}$ is the collection of all vectors that can be expressed in terms of $v_1,...,v_p$ (ie. a linear combination)

In other words, it is the **set of all linear combinations**

let A be an $m\times n$ matrix, then the following statements are logically equivalent (either all true or all false)
1. For each $b$ in $\R^m$ the equation $Ax=b$ has a solution
2. Each $b$ in $\R^m$ is a linear combination of the columns of $a$ (the Span  of the columns of $a$ is equal to the $m$th dimensional real space).
3. The columns of $a$ span $\R^m$
A has a pivot position in every row
